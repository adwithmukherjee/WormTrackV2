{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jgak12/WormTrackV2/blob/main/WormTrackerV2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eAlGCrWHBSQ-"
      },
      "source": [
        "WORM TRACKER"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QTsNmevRXlp9"
      },
      "source": [
        "TO DO:\n",
        "\n",
        "* pull small format images from large images based on difference tracked location (done)\n",
        "* Find a way to relabel all images in the img file so they can be marked which have worms and which dont (kindof done?)\n",
        "* If time, write quick file relabeling program that gives all files numbered sequence (done\n",
        "* Write function that turns video into series of .jpg with ordered filenames\n",
        "* Make user-interface to select intitial worm positions/#worms\n",
        "* UI to select desired outputs\n",
        "* UI to select type of experiment\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#On startup in vscode:\n",
        "#Mac: source /path/to/venv/bin/activate\n",
        "#Windows: \\pathtovenv\\Scripts\\activate"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "wRUVp-X_BemI"
      },
      "outputs": [],
      "source": [
        "# %pip install -U -q PyDrive\n",
        "# from pydrive.auth import GoogleAuth\n",
        "# from pydrive.drive import GoogleDrive\n",
        "# from google.colab import auth\n",
        "# from oauth2client.client import GoogleCredentials\n",
        "# # Authenticate and create the PyDrive client.\n",
        "# # This only needs to be done once per notebook. Use your UPR account \n",
        "# auth.authenticate_user()\n",
        "# gauth = GoogleAuth()\n",
        "# gauth.credentials = GoogleCredentials.get_application_default()\n",
        "# drive = GoogleDrive(gauth)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "SbZ5rE2QB-io"
      },
      "outputs": [],
      "source": [
        "def loadFromDrive(file_id, local_name):\n",
        "  downloaded = drive.CreateFile({'id': file_id})\n",
        "  downloaded.GetContentFile(local_name)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eIvbGi0DD5s1"
      },
      "source": [
        "Read Data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eyFNQ8_AFXAg"
      },
      "source": [
        "Forget that noise, I'm trying from scratch\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4zv9j9KdFbj_",
        "outputId": "8bf095cf-acef-49fa-d4ab-daea1fbb2b39"
      },
      "outputs": [],
      "source": [
        "\n",
        "###install protobuf somehow\n",
        "\n",
        "\n",
        "#import tensorflow as tf\n",
        "\n",
        "# %pip install -U -q PyDrive\n",
        "# from pydrive.auth import GoogleAuth\n",
        "# from pydrive.drive import GoogleDrive\n",
        "# from google.colab import auth\n",
        "# from oauth2client.client import GoogleCredentials\n",
        "# # Authenticate and create the PyDrive client.\n",
        "# # This only needs to be done once per notebook. Use your UPR account \n",
        "# auth.authenticate_user()\n",
        "# gauth = GoogleAuth()\n",
        "# gauth.credentials = GoogleCredentials.get_application_default()\n",
        "# drive = GoogleDrive(gauth)\n",
        "\n",
        "#%pip install pycocotools\n",
        "#%git clone https://github.com/tensorflow/models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "id": "esEx5cVFPhTJ",
        "outputId": "cc87ac7a-dded-4e85-c665-4eca2622fb1c"
      },
      "outputs": [],
      "source": [
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVWnx9Z1hHYT"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "HYtc7rRsMYwg"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting tensorflowNote: you may need to restart the kernel to use updated packages.\n",
            "\n",
            "  Downloading tensorflow-2.8.0-cp310-cp310-win_amd64.whl (438.0 MB)\n",
            "     -------------------------------------- 438.0/438.0 MB 2.1 MB/s eta 0:00:00\n",
            "Collecting tf-estimator-nightly==2.8.0.dev2021122109\n",
            "  Downloading tf_estimator_nightly-2.8.0.dev2021122109-py2.py3-none-any.whl (462 kB)\n",
            "     ------------------------------------- 462.5/462.5 KB 28.3 MB/s eta 0:00:00\n",
            "Collecting absl-py>=0.4.0\n",
            "  Downloading absl_py-1.0.0-py3-none-any.whl (126 kB)\n",
            "     -------------------------------------- 126.7/126.7 KB 7.8 MB/s eta 0:00:00\n",
            "Requirement already satisfied: keras<2.9,>=2.8.0rc0 in c:\\users\\jmara\\onedrive\\documents\\github\\wormtrackv2\\.wormvenv\\lib\\site-packages (from tensorflow) (2.8.0)\n",
            "Collecting gast>=0.2.1\n",
            "  Downloading gast-0.5.3-py3-none-any.whl (19 kB)\n",
            "Collecting keras-preprocessing>=1.1.1\n",
            "  Downloading Keras_Preprocessing-1.1.2-py2.py3-none-any.whl (42 kB)\n",
            "     ---------------------------------------- 42.6/42.6 KB 2.2 MB/s eta 0:00:00\n",
            "Collecting google-pasta>=0.1.1\n",
            "  Downloading google_pasta-0.2.0-py3-none-any.whl (57 kB)\n",
            "     ---------------------------------------- 57.5/57.5 KB 3.1 MB/s eta 0:00:00\n",
            "Collecting tensorflow-io-gcs-filesystem>=0.23.1\n",
            "  Downloading tensorflow_io_gcs_filesystem-0.25.0-cp310-cp310-win_amd64.whl (1.5 MB)\n",
            "     ---------------------------------------- 1.5/1.5 MB 30.7 MB/s eta 0:00:00\n",
            "Collecting libclang>=9.0.1\n",
            "  Downloading libclang-14.0.1-py2.py3-none-win_amd64.whl (14.2 MB)\n",
            "     --------------------------------------- 14.2/14.2 MB 22.6 MB/s eta 0:00:00\n",
            "Requirement already satisfied: setuptools in c:\\users\\jmara\\onedrive\\documents\\github\\wormtrackv2\\.wormvenv\\lib\\site-packages (from tensorflow) (58.1.0)\n",
            "Collecting tensorboard<2.9,>=2.8\n",
            "  Downloading tensorboard-2.8.0-py3-none-any.whl (5.8 MB)\n",
            "     ---------------------------------------- 5.8/5.8 MB 28.3 MB/s eta 0:00:00\n",
            "Collecting protobuf>=3.9.2\n",
            "  Using cached protobuf-3.20.1-cp310-cp310-win_amd64.whl (903 kB)\n",
            "Collecting flatbuffers>=1.12\n",
            "  Downloading flatbuffers-2.0-py2.py3-none-any.whl (26 kB)\n",
            "Requirement already satisfied: six>=1.12.0 in c:\\users\\jmara\\onedrive\\documents\\github\\wormtrackv2\\.wormvenv\\lib\\site-packages (from tensorflow) (1.16.0)\n",
            "Requirement already satisfied: numpy>=1.20 in c:\\users\\jmara\\onedrive\\documents\\github\\wormtrackv2\\.wormvenv\\lib\\site-packages (from tensorflow) (1.22.3)\n",
            "Collecting grpcio<2.0,>=1.24.3\n",
            "  Downloading grpcio-1.44.0-cp310-cp310-win_amd64.whl (3.4 MB)\n",
            "     ---------------------------------------- 3.4/3.4 MB 24.5 MB/s eta 0:00:00\n",
            "Collecting h5py>=2.9.0\n",
            "  Downloading h5py-3.6.0-cp310-cp310-win_amd64.whl (2.8 MB)\n",
            "     ---------------------------------------- 2.8/2.8 MB 25.3 MB/s eta 0:00:00\n",
            "Collecting astunparse>=1.6.0\n",
            "  Downloading astunparse-1.6.3-py2.py3-none-any.whl (12 kB)\n",
            "Collecting wrapt>=1.11.0\n",
            "  Downloading wrapt-1.14.0-cp310-cp310-win_amd64.whl (36 kB)\n",
            "Collecting opt-einsum>=2.3.2\n",
            "  Downloading opt_einsum-3.3.0-py3-none-any.whl (65 kB)\n",
            "     ---------------------------------------- 65.5/65.5 KB 3.7 MB/s eta 0:00:00\n",
            "Collecting typing-extensions>=3.6.6\n",
            "  Downloading typing_extensions-4.2.0-py3-none-any.whl (24 kB)\n",
            "Collecting termcolor>=1.1.0\n",
            "  Downloading termcolor-1.1.0.tar.gz (3.9 kB)\n",
            "  Preparing metadata (setup.py): started\n",
            "  Preparing metadata (setup.py): finished with status 'done'\n",
            "Collecting wheel<1.0,>=0.23.0\n",
            "  Downloading wheel-0.37.1-py2.py3-none-any.whl (35 kB)\n",
            "Collecting tensorboard-plugin-wit>=1.6.0\n",
            "  Downloading tensorboard_plugin_wit-1.8.1-py3-none-any.whl (781 kB)\n",
            "     ------------------------------------- 781.3/781.3 KB 24.9 MB/s eta 0:00:00\n",
            "Collecting google-auth<3,>=1.6.3\n",
            "  Using cached google_auth-2.6.6-py2.py3-none-any.whl (156 kB)\n",
            "Collecting google-auth-oauthlib<0.5,>=0.4.1\n",
            "  Downloading google_auth_oauthlib-0.4.6-py2.py3-none-any.whl (18 kB)\n",
            "Collecting markdown>=2.6.8\n",
            "  Downloading Markdown-3.3.6-py3-none-any.whl (97 kB)\n",
            "     ---------------------------------------- 97.8/97.8 KB ? eta 0:00:00\n",
            "Collecting werkzeug>=0.11.15\n",
            "  Downloading Werkzeug-2.1.1-py3-none-any.whl (224 kB)\n",
            "     ------------------------------------- 224.7/224.7 KB 13.4 MB/s eta 0:00:00\n",
            "Collecting requests<3,>=2.21.0\n",
            "  Using cached requests-2.27.1-py2.py3-none-any.whl (63 kB)\n",
            "Collecting tensorboard-data-server<0.7.0,>=0.6.0\n",
            "  Downloading tensorboard_data_server-0.6.1-py3-none-any.whl (2.4 kB)\n",
            "Collecting cachetools<6.0,>=2.0.0\n",
            "  Using cached cachetools-5.0.0-py3-none-any.whl (9.1 kB)\n",
            "Collecting rsa<5,>=3.1.4\n",
            "  Using cached rsa-4.8-py3-none-any.whl (39 kB)\n",
            "Collecting pyasn1-modules>=0.2.1\n",
            "  Using cached pyasn1_modules-0.2.8-py2.py3-none-any.whl (155 kB)\n",
            "Collecting requests-oauthlib>=0.7.0\n",
            "  Downloading requests_oauthlib-1.3.1-py2.py3-none-any.whl (23 kB)\n",
            "Collecting urllib3<1.27,>=1.21.1\n",
            "  Using cached urllib3-1.26.9-py2.py3-none-any.whl (138 kB)\n",
            "Collecting idna<4,>=2.5\n",
            "  Using cached idna-3.3-py3-none-any.whl (61 kB)\n",
            "Collecting certifi>=2017.4.17\n",
            "  Using cached certifi-2021.10.8-py2.py3-none-any.whl (149 kB)\n",
            "Collecting charset-normalizer~=2.0.0\n",
            "  Using cached charset_normalizer-2.0.12-py3-none-any.whl (39 kB)\n",
            "Collecting pyasn1<0.5.0,>=0.4.6\n",
            "  Using cached pyasn1-0.4.8-py2.py3-none-any.whl (77 kB)\n",
            "Collecting oauthlib>=3.0.0\n",
            "  Downloading oauthlib-3.2.0-py3-none-any.whl (151 kB)\n",
            "     ---------------------------------------- 151.5/151.5 KB ? eta 0:00:00\n",
            "Using legacy 'setup.py install' for termcolor, since package 'wheel' is not installed.\n",
            "Installing collected packages: tf-estimator-nightly, termcolor, tensorboard-plugin-wit, pyasn1, libclang, flatbuffers, certifi, wrapt, wheel, werkzeug, urllib3, typing-extensions, tensorflow-io-gcs-filesystem, tensorboard-data-server, rsa, pyasn1-modules, protobuf, opt-einsum, oauthlib, markdown, keras-preprocessing, idna, h5py, grpcio, google-pasta, gast, charset-normalizer, cachetools, absl-py, requests, google-auth, astunparse, requests-oauthlib, google-auth-oauthlib, tensorboard, tensorflow\n",
            "  Running setup.py install for termcolor: started\n",
            "  Running setup.py install for termcolor: finished with status 'done'\n",
            "Successfully installed absl-py-1.0.0 astunparse-1.6.3 cachetools-5.0.0 certifi-2021.10.8 charset-normalizer-2.0.12 flatbuffers-2.0 gast-0.5.3 google-auth-2.6.6 google-auth-oauthlib-0.4.6 google-pasta-0.2.0 grpcio-1.44.0 h5py-3.6.0 idna-3.3 keras-preprocessing-1.1.2 libclang-14.0.1 markdown-3.3.6 oauthlib-3.2.0 opt-einsum-3.3.0 protobuf-3.20.1 pyasn1-0.4.8 pyasn1-modules-0.2.8 requests-2.27.1 requests-oauthlib-1.3.1 rsa-4.8 tensorboard-2.8.0 tensorboard-data-server-0.6.1 tensorboard-plugin-wit-1.8.1 tensorflow-2.8.0 tensorflow-io-gcs-filesystem-0.25.0 termcolor-1.1.0 tf-estimator-nightly-2.8.0.dev2021122109 typing-extensions-4.2.0 urllib3-1.26.9 werkzeug-2.1.1 wheel-0.37.1 wrapt-1.14.0\n"
          ]
        }
      ],
      "source": [
        "#Probs wont need this at all\n",
        "#%pip install labelImg\n",
        "\n",
        "#%pip install -U scikit-image\n",
        "#%pip install -U scikit-learn\n",
        "#%pip install pandas\n",
        "#%pip install keras\n",
        "#%pip install tensorflow\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "hUfOl_e6xytJ"
      },
      "outputs": [],
      "source": [
        "#Import everything\n",
        "\n",
        "import glob, os \n",
        "import skimage\n",
        "from skimage import io, transform\n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from keras.models import Sequential ##Might change this to Convolutional\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense\n",
        "#from keras.optimizers import SGD, Adam\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.layers.convolutional import Convolution2D, MaxPooling2D, Convolution3D\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from sklearn.preprocessing import scale\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "plt.rcParams['axes.grid']=False\n",
        "import matplotlib as mpl\n",
        "mpl.rcParams['image.cmap'] = 'viridis'\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 240
        },
        "id": "GN809ulOAhTE",
        "outputId": "09bb04a0-df8b-422a-9780-2b9c953568ec"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/WormTracker/WormImgs/wormImgLowQ_181.jpg'",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\jmara\\OneDrive\\Documents\\GitHub\\WormTrackV2\\WormTrackerV2.ipynb Cell 14'\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/jmara/OneDrive/Documents/GitHub/WormTrackV2/WormTrackerV2.ipynb#ch0000012?line=0'>1</a>\u001b[0m img1\u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39;49mimread(\u001b[39m'\u001b[39;49m\u001b[39m/content/drive/MyDrive/WormTracker/WormImgs/wormImgLowQ_181.jpg\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jmara/OneDrive/Documents/GitHub/WormTrackV2/WormTrackerV2.ipynb#ch0000012?line=1'>2</a>\u001b[0m img2\u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39mimread(\u001b[39m'\u001b[39m\u001b[39m/content/drive/MyDrive/WormTracker/WormImgs/wormImgLowQ_182.jpg\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jmara/OneDrive/Documents/GitHub/WormTrackV2/WormTrackerV2.ipynb#ch0000012?line=3'>4</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mframe_compare\u001b[39m(img1,img2,showImg\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jmara/OneDrive/Documents/GitHub/WormTrackV2/WormTrackerV2.ipynb#ch0000012?line=4'>5</a>\u001b[0m   \u001b[39m#plt.imshow(img1)\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jmara/OneDrive/Documents/GitHub/WormTrackV2/WormTrackerV2.ipynb#ch0000012?line=5'>6</a>\u001b[0m   \u001b[39m#plt.imshow(img2)\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jmara/OneDrive/Documents/GitHub/WormTrackV2/WormTrackerV2.ipynb#ch0000012?line=6'>7</a>\u001b[0m   \u001b[39m#sum=img2-img1\u001b[39;00m\n",
            "File \u001b[1;32mc:\\Users\\jmara\\OneDrive\\Documents\\GitHub\\.Wormvenv\\lib\\site-packages\\matplotlib\\pyplot.py:2139\u001b[0m, in \u001b[0;36mimread\u001b[1;34m(fname, format)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/jmara/OneDrive/Documents/GitHub/.Wormvenv/lib/site-packages/matplotlib/pyplot.py?line=2136'>2137</a>\u001b[0m \u001b[39m@_copy_docstring_and_deprecators\u001b[39m(matplotlib\u001b[39m.\u001b[39mimage\u001b[39m.\u001b[39mimread)\n\u001b[0;32m   <a href='file:///c%3A/Users/jmara/OneDrive/Documents/GitHub/.Wormvenv/lib/site-packages/matplotlib/pyplot.py?line=2137'>2138</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mimread\u001b[39m(fname, \u001b[39mformat\u001b[39m\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m-> <a href='file:///c%3A/Users/jmara/OneDrive/Documents/GitHub/.Wormvenv/lib/site-packages/matplotlib/pyplot.py?line=2138'>2139</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m matplotlib\u001b[39m.\u001b[39;49mimage\u001b[39m.\u001b[39;49mimread(fname, \u001b[39mformat\u001b[39;49m)\n",
            "File \u001b[1;32mc:\\Users\\jmara\\OneDrive\\Documents\\GitHub\\.Wormvenv\\lib\\site-packages\\matplotlib\\image.py:1560\u001b[0m, in \u001b[0;36mimread\u001b[1;34m(fname, format)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/jmara/OneDrive/Documents/GitHub/.Wormvenv/lib/site-packages/matplotlib/image.py?line=1557'>1558</a>\u001b[0m                 response \u001b[39m=\u001b[39m io\u001b[39m.\u001b[39mBytesIO(response\u001b[39m.\u001b[39mread())\n\u001b[0;32m   <a href='file:///c%3A/Users/jmara/OneDrive/Documents/GitHub/.Wormvenv/lib/site-packages/matplotlib/image.py?line=1558'>1559</a>\u001b[0m             \u001b[39mreturn\u001b[39;00m imread(response, \u001b[39mformat\u001b[39m\u001b[39m=\u001b[39mext)\n\u001b[1;32m-> <a href='file:///c%3A/Users/jmara/OneDrive/Documents/GitHub/.Wormvenv/lib/site-packages/matplotlib/image.py?line=1559'>1560</a>\u001b[0m \u001b[39mwith\u001b[39;00m img_open(fname) \u001b[39mas\u001b[39;00m image:\n\u001b[0;32m   <a href='file:///c%3A/Users/jmara/OneDrive/Documents/GitHub/.Wormvenv/lib/site-packages/matplotlib/image.py?line=1560'>1561</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m (_pil_png_to_float_array(image)\n\u001b[0;32m   <a href='file:///c%3A/Users/jmara/OneDrive/Documents/GitHub/.Wormvenv/lib/site-packages/matplotlib/image.py?line=1561'>1562</a>\u001b[0m             \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(image, PIL\u001b[39m.\u001b[39mPngImagePlugin\u001b[39m.\u001b[39mPngImageFile) \u001b[39melse\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/jmara/OneDrive/Documents/GitHub/.Wormvenv/lib/site-packages/matplotlib/image.py?line=1562'>1563</a>\u001b[0m             pil_to_array(image))\n",
            "File \u001b[1;32mc:\\Users\\jmara\\OneDrive\\Documents\\GitHub\\.Wormvenv\\lib\\site-packages\\PIL\\Image.py:3068\u001b[0m, in \u001b[0;36mopen\u001b[1;34m(fp, mode, formats)\u001b[0m\n\u001b[0;32m   <a href='file:///c%3A/Users/jmara/OneDrive/Documents/GitHub/.Wormvenv/lib/site-packages/PIL/Image.py?line=3064'>3065</a>\u001b[0m     filename \u001b[39m=\u001b[39m fp\n\u001b[0;32m   <a href='file:///c%3A/Users/jmara/OneDrive/Documents/GitHub/.Wormvenv/lib/site-packages/PIL/Image.py?line=3066'>3067</a>\u001b[0m \u001b[39mif\u001b[39;00m filename:\n\u001b[1;32m-> <a href='file:///c%3A/Users/jmara/OneDrive/Documents/GitHub/.Wormvenv/lib/site-packages/PIL/Image.py?line=3067'>3068</a>\u001b[0m     fp \u001b[39m=\u001b[39m builtins\u001b[39m.\u001b[39;49mopen(filename, \u001b[39m\"\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m\"\u001b[39;49m)\n\u001b[0;32m   <a href='file:///c%3A/Users/jmara/OneDrive/Documents/GitHub/.Wormvenv/lib/site-packages/PIL/Image.py?line=3068'>3069</a>\u001b[0m     exclusive_fp \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m   <a href='file:///c%3A/Users/jmara/OneDrive/Documents/GitHub/.Wormvenv/lib/site-packages/PIL/Image.py?line=3070'>3071</a>\u001b[0m \u001b[39mtry\u001b[39;00m:\n",
            "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/WormTracker/WormImgs/wormImgLowQ_181.jpg'"
          ]
        }
      ],
      "source": [
        "\n",
        "\n",
        "img1= plt.imread('/content/drive/MyDrive/WormTracker/WormImgs/wormImgLowQ_181.jpg')\n",
        "img2= plt.imread('/content/drive/MyDrive/WormTracker/WormImgs/wormImgLowQ_182.jpg')\n",
        "\n",
        "def frame_compare(img1,img2,showImg=False):\n",
        "  #plt.imshow(img1)\n",
        "  #plt.imshow(img2)\n",
        "  #sum=img2-img1\n",
        "  sum= np.zeros(img2.shape)\n",
        "\n",
        "  rowLen=sum.shape[0]\n",
        "  colLen=sum.shape[1]\n",
        "\n",
        "  for pixelx in range(0,colLen):\n",
        "    for pixely in range(0,rowLen):\n",
        "      for pixelrgb in range(0,3):\n",
        "        if img2[pixely,pixelx,pixelrgb] >= img1[pixely,pixelx,pixelrgb]:\n",
        "          sum[pixely,pixelx,pixelrgb]= img2[pixely,pixelx,pixelrgb]-img1[pixely,pixelx,pixelrgb]\n",
        "        else:\n",
        "          sum[pixely,pixelx,pixelrgb]= img1[pixely,pixelx,pixelrgb]-img2[pixely,pixelx,pixelrgb]\n",
        "\n",
        "  ##print(img1[1:5,1:5])\n",
        "  #print(img2[1:5,1:5])\n",
        "  #print(sum[1:5,1:5])\n",
        "\n",
        "  #print(sum.shape[0])\n",
        "\n",
        "\n",
        "  dif_sens=40 #remove later\n",
        "  dif_sense= 10\n",
        "\n",
        "  motion_sensitivity=1.1 * 10\n",
        "\n",
        "  xavg=0\n",
        "  yavg=0\n",
        "\n",
        "\n",
        "  #for xx in range(0, sum.shape[1]):\n",
        "  # for yy in range(0, sum.shape[0]):\n",
        "  #   for zz in range(0, sum.shape[2]):\n",
        "  #     if sum[yy, xx, zz]<= dif_sens:\n",
        "  #        sum[yy,xx,zz]=0\n",
        "\n",
        "\n",
        "  #print(sum[0:10, 0:10])\n",
        "\n",
        "  difArray= np.zeros((sum.shape[0],sum.shape[1]))\n",
        "  #print(difArray.shape)\n",
        "  totPixelDif=0;\n",
        "  numNonZpixels=0\n",
        "  for pixelx in range(0,colLen):\n",
        "    for pixely in range(0,rowLen):\n",
        "      for pixelrgb in range(0,3):\n",
        "        chanPixelDif= sum[pixely,pixelx,pixelrgb]\n",
        "        totPixelDif = totPixelDif + chanPixelDif\n",
        "      if totPixelDif > dif_sense*3:\n",
        "        #print('hi')\n",
        "        difArray[pixely,pixelx]=totPixelDif\n",
        "      totPixelDif=0\n",
        "\n",
        "  #print(difArray)\n",
        "  difArray[:,:]= difArray[:,:]/3\n",
        "  #print(difArray)\n",
        "\n",
        "  #print(difArray)\n",
        "  weightTot=0\n",
        "  for pixelx in range(0,colLen):\n",
        "    for pixely in range(0,rowLen):\n",
        "      xavg=xavg + (difArray[pixely,pixelx]*pixelx)\n",
        "      yavg=yavg + (difArray[pixely,pixelx]*pixely)\n",
        "\n",
        "      weightTot= weightTot + difArray[pixely,pixelx]\n",
        "\n",
        "  if xavg>motion_sensitivity:\n",
        "    xavg=round(xavg/weightTot)\n",
        "    yavg=round(yavg/weightTot)\n",
        "    pos=[xavg, yavg]\n",
        "  else: #returns 00 if change below threshold\n",
        "    xavg=1\n",
        "    yavg=1\n",
        "    pos=[xavg, yavg]\n",
        "\n",
        "  size=3\n",
        "\n",
        "  #imshow\n",
        "  #print(difArray)\n",
        "  if showImg==True:\n",
        "    plt.subplot(2,2,1)\n",
        "    plt.imshow(sum)\n",
        "    plt.subplot(2,2,2)\n",
        "    plt.imshow(difArray)\n",
        "    plt.subplot(2,2,3)\n",
        "    difArrayMarked= difArray\n",
        "    #difArrayMarked[round(yavg-size):round(yavg+size), round(xavg-size):round(xavg+size)]= 1000000\n",
        "    plt.imshow(difArrayMarked)\n",
        "    print(xavg,yavg)\n",
        "    plt.scatter(xavg,yavg)\n",
        "    plt.subplot(2,2,4)\n",
        "    plt.imshow(img2)\n",
        "\n",
        "  plt.subplot(1,1,1)\n",
        "  plt.imshow(img2)\n",
        "  plt.scatter(xavg,yavg)\n",
        "\n",
        "  return pos\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fN-a900pxOed",
        "outputId": "273226dd-cbd8-4def-d71e-9ae5468ad9c1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[-1  3  3]\n",
            "(400, 512, 3)\n"
          ]
        }
      ],
      "source": [
        "a=np.array([5,5,5])\n",
        "b=np.array([6,2,2])\n",
        "c=a-b\n",
        "print(c)\n",
        "print(img1.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6hJJRvTz0l0P"
      },
      "outputs": [],
      "source": [
        "def dataset(file_list, flattened=False): #,size=(300,180)\n",
        "\tdata = []\n",
        "\tfor i, file in enumerate(file_list):\n",
        "\t\timage = io.imread(file)\n",
        "\t\t#image = transform.resize(image, size, mode='constant')\n",
        "\t\tif flattened:\n",
        "\t\t\timage = image.flatten()\n",
        "\n",
        "\t\tdata.append(image)\n",
        "\n",
        "\t#labels = [1 if f.split(\"/\")[-1][0] == 'P' else 0 for f in file_list]\n",
        "\n",
        "\treturn np.array(data)#, np.array(labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 258
        },
        "id": "16_cde0yxeqX",
        "outputId": "746c2d73-45b2-4f95-bce7-d8b7c29a7851"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-3-7a1e196a36cd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#loading list of images\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"/content/drive/MyDrive/WormTracker/WormImgs/\"\u001b[0m \u001b[0;31m#path to image folder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mimlist\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mglob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglob\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'*.jpg'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#pulls list of all files in folder\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Dataset contains {} images'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#returns how many images in list\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mlistlen\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'glob' is not defined"
          ]
        }
      ],
      "source": [
        "#loading list of images\n",
        "path=\"/content/drive/MyDrive/WormTracker/WormImgs/\" #path to image folder\n",
        "imlist = glob.glob(os.path.join(path, '*.jpg')) #pulls list of all files in folder\n",
        "print('Dataset contains {} images'.format(len(imlist))) #returns how many images in list\n",
        "listlen= len(imlist)\n",
        "\n",
        "print(imlist) #For some reason, glob pulls the files in a wrong order\n",
        "imlist.sort() #this sorts them alphabetically ASSUMES IMAGES ARE NUMBERED ALREADY/PROPERLY\n",
        "print(imlist)\n",
        "\n",
        "# Load the data. The same as pollen dataset read-skimage (May take a few seconds)\n",
        "#data,labels = dataset(imlist) \n",
        "data= dataset(imlist)\n",
        "data= np.array(data)\n",
        "#print(data)\n",
        "#this loads the images as a numpy ndarray with each image represented as matrix of pixel values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 186
        },
        "id": "VgIKxiWd1SsM",
        "outputId": "863809ef-df51-4aff-97a2-75782118c082"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-2-14200ebf44aa>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#print(img1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'data' is not defined"
          ]
        }
      ],
      "source": [
        "#print(img1)\n",
        "print(data.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kU2ns-Bc4-Gx"
      },
      "outputs": [],
      "source": [
        "stepSize=25\n",
        "#poslist= np.zeros((listlen-1, 2)) #x,y\n",
        "poslist= np.empty((0,2), int)\n",
        "\n",
        "\n",
        "for i in range(0,listlen-1,stepSize):\n",
        "  img1=data[i,:,:,:]\n",
        "  img2=data[i+1,:,:,:]\n",
        "\n",
        "  #frame_compare\n",
        "  pos=frame_compare(img1,img2)\n",
        "  print(pos)\n",
        "  \n",
        "  poslist= np.append(poslist,np.array([pos]),axis=0)\n",
        "  #All i want to do is add new paired x and y values to a new row... how is this\n",
        "  #so much to ask\n",
        "\n",
        "\n",
        "\n",
        "print(poslist)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lLq8Owpz4cRB"
      },
      "outputs": [],
      "source": [
        "plt.scatter(poslist[:,0],poslist[:,1] )\n",
        "plt.gca().invert_yaxis()\n",
        "plt.xlim([0, 512])\n",
        "plt.ylim([0,400])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3lLdIHrXOY9M"
      },
      "outputs": [],
      "source": [
        "def get_surround_image(img, xpos, ypos):\n",
        "  xlen=img.shape(0)\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TJcLLEvIR-HO"
      },
      "outputs": [],
      "source": [
        "def pullSub(inImg, pos, outputSize):\n",
        "  if outputSize[0]>inImg.shape[0] or outputSize[1]>inImg.shape[1]:\n",
        "    return \"output bigger than image\"\n",
        "  xmin=int(pos[0]-(outputSize[0]/2))\n",
        "  xmax=int(pos[0]+(outputSize[0]/2))\n",
        "  ymin=int(pos[1]-(outputSize[1]/2))\n",
        "  ymax=int(pos[1]+(outputSize[1]/2))\n",
        "  if xmin<0:\n",
        "    xmin=0\n",
        "  if xmax>(inImg.shape[1]):\n",
        "    xmax=(inImg.shape[1]-1)\n",
        "  if ymin<0:\n",
        "    ymin=0\n",
        "  if ymax>(inImg.shape[0]):\n",
        "    ymax=(inImg.shape[0]-1)\n",
        "\n",
        "  subImg=inImg[ymin:ymax, xmin:xmax]\n",
        "\n",
        "  return subImg\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_qc3s4cCFhrf"
      },
      "outputs": [],
      "source": [
        "img1= plt.imread('/content/drive/MyDrive/WormTracker/WormImgs/wormImgLowQ_187.jpg')\n",
        "img2= plt.imread('/content/drive/MyDrive/WormTracker/WormImgs/wormImgLowQ_188.jpg')\n",
        "pos1=frame_compare(img1,img2)\n",
        "plt.imshow(img1)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mvtMGP6EGXM7"
      },
      "outputs": [],
      "source": [
        "a= pullSub(img2, pos1, [64,64])\n",
        "plt.imshow(a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Q-PuYoPaMT_t"
      },
      "outputs": [],
      "source": [
        "\n",
        "data = '/content/drive/My Drive/WormTracker/WormImgs/'\n",
        "#ldseg=np.array(os.listdir(data))\n",
        "i = 1\n",
        "\n",
        "\n",
        "#loading list of images\n",
        "path=\"/content/drive/MyDrive/WormTracker/WormImgs/\" #path to image folder\n",
        "\n",
        "def numToIndex(n,numDigits):\n",
        "  out=''\n",
        "  num=str(n)\n",
        "  for i in range(0,numDigits-len(num)):\n",
        "    out= out+'0'\n",
        "  out= out+ num\n",
        "  return out\n",
        "\n",
        "def sort_rename(path,):\n",
        "  #Takes in a path to a file of numbered, sequential images\n",
        "  #renames all the files in the directory with '_*' sequential number from 1:n added\n",
        "\n",
        "  ldseg = glob.glob(os.path.join(path, '*.jpg')) #pulls list of all files in folder\n",
        "  print('Dataset contains {} images'.format(len(ldseg))) #returns how many images in list\n",
        "  listlen= len(ldseg)\n",
        "\n",
        "  print(ldseg) #For some reason, glob pulls the files in a wrong order\n",
        "  ldseg.sort() #this sorts them alphabetically ASSUMES IMAGES ARE NUMBERED ALREADY/PROPERLY\n",
        "  print(ldseg)\n",
        "\n",
        "  i=1\n",
        "  for filename in ldseg:\n",
        "    dst =  filename.split('_')[0] + '_' + numToIndex(i,4) + '.jpg' #removes original index marker after a \"_\"\n",
        "    print(dst)\n",
        "    print(filename)\n",
        "    src =filename\n",
        "    print(src)\n",
        "    print(dst)\n",
        "    os.rename(src, dst)\n",
        "    i += 1\n",
        "\n",
        "sort_rename(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Y5-u9jBdOVMM"
      },
      "outputs": [],
      "source": [
        "#JUST A LITTLE TEST BLOCK\n",
        "ldseg = glob.glob(os.path.join(path, '*.jpg')) #pulls list of all files in folder\n",
        "print('Dataset contains {} images'.format(len(ldseg))) #returns how many images in list\n",
        "listlen= len(ldseg)\n",
        "\n",
        "print(ldseg) #For some reason, glob pulls the files in a wrong order\n",
        "ldseg.sort() #this sorts them alphabetically ASSUMES IMAGES ARE NUMBERED ALREADY/PROPERLY\n",
        "print(ldseg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QhRFnr9M4tFe"
      },
      "source": [
        "NOW THE NEURAL NETWORK:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Whhxgiq76CpJ"
      },
      "outputs": [],
      "source": [
        "# Create a training and testing dataset with 25% of the samples\n",
        "X_train, X_test, y_train, y_test = train_test_split(data,labels, test_size=.25,random_state=0,)\n",
        "#ids=np.array(range(data.shape[0]))\n",
        "#X_train, X_ids, y_train, y_ids = train_test_split(data,ids, test_size=.25,random_state=0,)\n",
        "#X_test=labels[X_ids]; y_test=labels[y_ids]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6DWhGf-46BxY"
      },
      "outputs": [],
      "source": [
        "# check shape of the input image to fit with the network \n",
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HzUohCNl5jqH"
      },
      "outputs": [],
      "source": [
        "import skimage\n",
        "X_train_resized = np.asarray([skimage.transform.resize(image, (224,224)) for image in X_train])\n",
        "X_test_resized = np.asarray([skimage.transform.resize(image, (224,224)) for image in X_test])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 222
        },
        "id": "XZ33bVFA5kXA",
        "outputId": "0b6342db-bad2-4cc6-f8f9-415b9332def2"
      },
      "outputs": [
        {
          "ename": "NameError",
          "evalue": "ignored",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-1f6d4fc9a53d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_train_encoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0my_test_encoded\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_categorical\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0my_train_encoded\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'to_categorical' is not defined"
          ]
        }
      ],
      "source": [
        "y_train_encoded = to_categorical(y_train)\n",
        "y_test_encoded = to_categorical(y_test)\n",
        "\n",
        "y_train_encoded.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9zVzQrXG47kR"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.layers import Dense, Activation,Dropout,Conv2D, MaxPooling2D,BatchNormalization, Flatten\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.metrics import categorical_crossentropy\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "from tensorflow.keras.applications import imagenet_utils\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.models import Model, load_model, Sequential\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "\n",
        "\n",
        "train_gen=ImageDataGenerator(preprocessing_function=keras.applications.mobilenet.preprocess_input,\n",
        "                horizontal_flip=True,\n",
        "                samplewise_center=True,\n",
        "                width_shift_range=.2,\n",
        "                height_shift_range=.2,                \n",
        "                samplewise_std_normalization=True).flow(X_train_resized, y_train_encoded)\n",
        "#val_gen=ImageDataGenerator(preprocessing_function=keras.applications.mobilenet.preprocess_input,\n",
        "#                samplewise_center=True,                \n",
        "#                samplewise_std_normalization=True).flow(xValid, yValid, shuffle=False)        \n",
        "test_gen=ImageDataGenerator(preprocessing_function=keras.applications.mobilenet.preprocess_input,\n",
        "                samplewise_center=True,                \n",
        "                samplewise_std_normalization=True).flow(X_test_resized, y_test_encoded, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zCNxuWww5RCW"
      },
      "outputs": [],
      "source": [
        "Top=False\n",
        "weights=None\n",
        "layer_cut=-6\n",
        "lr_rate=.001\n",
        "rand_seed=128\n",
        "epochs=25\n",
        "mobile = tf.keras.applications.mobilenet.MobileNet( include_top=Top,\n",
        "                                                           input_shape=(224,224,3),\n",
        "                                                           pooling='avg', weights='imagenet',\n",
        "                                                          )  \n",
        "                 \n",
        "x=mobile.layers[layer_cut].output\n",
        "x = Flatten()(x)\n",
        "x=Dense(128, kernel_regularizer = regularizers.l2(l = 0.015), activation='relu')(x)\n",
        "\n",
        "x=Dropout(rate=.5, seed=rand_seed)(x)\n",
        "predictions=Dense (2, activation='softmax')(x)\n",
        "model = Model(inputs=mobile.input, outputs=predictions)\n",
        "        \n",
        "for layer in model.layers:\n",
        "    layer.trainable=True\n",
        "model.compile(Adam(lr=lr_rate), loss='categorical_crossentropy', metrics=['accuracy'])"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyMqKsJtE8pw24W1pRCt95iS",
      "include_colab_link": true,
      "mount_file_id": "1JGMc-_phb1unBHk_Mu4862LX-a_4kjXZ",
      "name": "WormTrackerV2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
