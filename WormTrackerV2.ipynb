{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/jgak12/WormTrackV2/blob/main/WormTrackerV2.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eAlGCrWHBSQ-"
      },
      "source": [
        "WORM TRACKER"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QTsNmevRXlp9"
      },
      "source": [
        "TO DO:\n",
        "\n",
        "* pull small format images from large images based on difference tracked location (done)\n",
        "* Find a way to relabel all images in the img file so they can be marked which have worms and which dont (kindof done?)\n",
        "* If time, write quick file relabeling program that gives all files numbered sequence (done\n",
        "* Write function that turns video into series of .jpg with ordered filenames\n",
        "* Make user-interface to select intitial worm positions/#worms\n",
        "* UI to select desired outputs\n",
        "* UI to select type of experiment\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "wRUVp-X_BemI"
      },
      "outputs": [],
      "source": [
        "#!pip install -U -q PyDrive\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "# Authenticate and create the PyDrive client.\n",
        "# This only needs to be done once per notebook. Use your UPR account \n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "def loadFromDrive(file_id, local_name):\n",
        "  downloaded = drive.CreateFile({'id': file_id})\n",
        "  downloaded.GetContentFile(local_name)\n",
        "  \n",
        "#from google.colab import drive\n",
        "#drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eIvbGi0DD5s1"
      },
      "source": [
        "Read Data\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EVWnx9Z1hHYT"
      },
      "source": [
        "# New Section"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "hUfOl_e6xytJ"
      },
      "outputs": [],
      "source": [
        "#Import everything\n",
        "\n",
        "import glob, os \n",
        "from skimage import io, transform\n",
        "import numpy as np \n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n",
        "from sklearn.model_selection import train_test_split\n",
        "import pandas as pd\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from keras.models import Sequential ##Might change this to Convolutional\n",
        "from keras.layers import Activation, Dropout, Flatten, Dense\n",
        "#from keras.optimizers import SGD, Adam\n",
        "from keras.utils.np_utils import to_categorical\n",
        "from keras.layers.convolutional import Convolution2D, MaxPooling2D, Convolution3D\n",
        "from keras.layers.convolutional import Conv2D\n",
        "from sklearn.preprocessing import scale\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "plt.rcParams['axes.grid']=False\n",
        "import matplotlib as mpl\n",
        "mpl.rcParams['image.cmap'] = 'viridis'\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "import HelpFxns\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "GN809ulOAhTE"
      },
      "outputs": [],
      "source": [
        "\n",
        "\n",
        "# img1= plt.imread('/content/drive/MyDrive/WormTracker/WormImgs/wormImgLowQ_0001.jpg')\n",
        "# img2= plt.imread('/content/drive/MyDrive/WormTracker/WormImgs/wormImgLowQ_0002.jpg')\n",
        "\n",
        "def frame_compare(img1,img2,showImg=False):\n",
        "  #plt.imshow(img1)\n",
        "  #plt.imshow(img2)\n",
        "  #sum=img2-img1\n",
        "  sum= np.zeros(img2.shape)\n",
        "\n",
        "  rowLen=sum.shape[0]\n",
        "  colLen=sum.shape[1]\n",
        "\n",
        "  for pixelx in range(0,colLen):\n",
        "    for pixely in range(0,rowLen): #here\n",
        "      for pixelrgb in range(0,3):\n",
        "        if img2[pixely,pixelx,pixelrgb] >= img1[pixely,pixelx,pixelrgb]:\n",
        "          sum[pixely,pixelx,pixelrgb]= img2[pixely,pixelx,pixelrgb]-img1[pixely,pixelx,pixelrgb]\n",
        "        else:\n",
        "          sum[pixely,pixelx,pixelrgb]= img1[pixely,pixelx,pixelrgb]-img2[pixely,pixelx,pixelrgb]\n",
        "\n",
        "  ##print(img1[1:5,1:5])\n",
        "  #print(img2[1:5,1:5])\n",
        "  #print(sum[1:5,1:5])\n",
        "\n",
        "  #print(sum.shape[0])\n",
        "\n",
        "\n",
        "  dif_sens=40 #remove later\n",
        "  dif_sense= 10\n",
        "\n",
        "  motion_sensitivity=1.1 * 10\n",
        "\n",
        "  xavg=0\n",
        "  yavg=0\n",
        "\n",
        "\n",
        "  #for xx in range(0, sum.shape[1]):\n",
        "  # for yy in range(0, sum.shape[0]):\n",
        "  #   for zz in range(0, sum.shape[2]):\n",
        "  #     if sum[yy, xx, zz]<= dif_sens:\n",
        "  #        sum[yy,xx,zz]=0\n",
        "\n",
        "\n",
        "  #print(sum[0:10, 0:10])\n",
        "\n",
        "  difArray= np.zeros((sum.shape[0],sum.shape[1]))\n",
        "  #print(difArray.shape)\n",
        "  totPixelDif=0;\n",
        "  numNonZpixels=0\n",
        "  for pixelx in range(0,colLen):\n",
        "    for pixely in range(0,rowLen):\n",
        "      for pixelrgb in range(0,3):\n",
        "        chanPixelDif= sum[pixely,pixelx,pixelrgb]\n",
        "        totPixelDif = totPixelDif + chanPixelDif\n",
        "      if totPixelDif > dif_sense*3:\n",
        "        #print('hi')\n",
        "        difArray[pixely,pixelx]=totPixelDif\n",
        "      totPixelDif=0\n",
        "\n",
        "  #print(difArray)\n",
        "  difArray[:,:]= difArray[:,:]/3\n",
        "  #print(difArray)\n",
        "\n",
        "  #print(difArray)\n",
        "  weightTot=0\n",
        "  for pixelx in range(0,colLen):\n",
        "    for pixely in range(0,rowLen):\n",
        "      xavg=xavg + (difArray[pixely,pixelx]*pixelx)\n",
        "      yavg=yavg + (difArray[pixely,pixelx]*pixely)\n",
        "\n",
        "      weightTot= weightTot + difArray[pixely,pixelx]\n",
        "\n",
        "  if xavg>motion_sensitivity:\n",
        "    xavg=round(xavg/weightTot)\n",
        "    yavg=round(yavg/weightTot)\n",
        "    pos=[xavg, yavg]\n",
        "  else: #returns 00 if change below threshold\n",
        "    xavg=1\n",
        "    yavg=1\n",
        "    pos=[xavg, yavg]\n",
        "\n",
        "  size=3\n",
        "\n",
        "  #imshow\n",
        "  #print(difArray)\n",
        "  if showImg==True:\n",
        "    plt.subplot(2,2,1)\n",
        "    plt.imshow(sum)\n",
        "    plt.subplot(2,2,2)\n",
        "    plt.imshow(difArray)\n",
        "    plt.subplot(2,2,3)\n",
        "    difArrayMarked= difArray\n",
        "    #difArrayMarked[round(yavg-size):round(yavg+size), round(xavg-size):round(xavg+size)]= 1000000\n",
        "    plt.imshow(difArrayMarked)\n",
        "    print(xavg,yavg)\n",
        "    plt.scatter(xavg,yavg)\n",
        "    plt.subplot(2,2,4)\n",
        "    plt.imshow(img2)\n",
        "\n",
        "  plt.subplot(1,1,1)\n",
        "  plt.imshow(img2)\n",
        "  plt.scatter(xavg,yavg)\n",
        "\n",
        "  return pos\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "Q-PuYoPaMT_t"
      },
      "outputs": [],
      "source": [
        "def numToIndex(n,numDigits):\n",
        "  out=''\n",
        "  num=str(n)\n",
        "  for i in range(0,numDigits-len(num)):\n",
        "    out= out+'0'\n",
        "  out= out+ num\n",
        "  return out\n",
        "\n",
        "def sort_rename(path,):\n",
        "  #Takes in a path to a file of numbered, sequential images\n",
        "  #renames all the files in the directory with '_*' sequential number from 1:n added\n",
        "\n",
        "  ldseg = glob.glob(os.path.join(path, '*.jpg')) #pulls list of all files in folder\n",
        "  print('Dataset contains {} images'.format(len(ldseg))) #returns how many images in list\n",
        "  listlen= len(ldseg)\n",
        "\n",
        "  print(ldseg) #For some reason, glob pulls the files in a wrong order\n",
        "  ldseg.sort() #this sorts them alphabetically ASSUMES IMAGES ARE NUMBERED ALREADY/PROPERLY\n",
        "  print(ldseg)\n",
        "\n",
        "  i=1\n",
        "  for filename in ldseg:\n",
        "    dst =  filename.split('_')[0] + '_' + numToIndex(i,4) + '.jpg' #removes original index marker after a \"_\"\n",
        "    print(dst)\n",
        "    print(filename)\n",
        "    src =filename\n",
        "    print(src)\n",
        "    print(dst)\n",
        "    os.rename(src, dst)\n",
        "    i += 1\n",
        "\n",
        "#sort_rename(path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "xXqzmCL_4eYo"
      },
      "outputs": [],
      "source": [
        "#video to imgs\n",
        "def vidToImgs(path, outputpath):\n",
        "  video= cv2.VideoCapture(path)\n",
        "  success=True\n",
        "  count=1\n",
        "  while success:\n",
        "    success, image = video.read()\n",
        "    cv2.imwrite(outputpath+ 'VideoFrame_{0}.jpg'.format(numToIndex(count,6)), image)\n",
        "    count+=1\n",
        "    print(\"Saved Image\" + str(count))\n",
        "\n",
        "#vidToImgs('/content/drive/MyDrive/WormTracker/wormVid/temp-04222022134339-0000.avi','/content/drive/MyDrive/WormTracker/VidOutput/')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "6hJJRvTz0l0P"
      },
      "outputs": [],
      "source": [
        "def dataset(file_list, size=(400,512), flattened=False): #,size=(300,180)\n",
        "\tdata = []\n",
        "\tfor i, file in enumerate(file_list):\n",
        "\t\timage = io.imread(file)\n",
        "\t\t#image = transform.resize(image, size, mode='constant')\n",
        "\t\tif flattened:\n",
        "\t\t\timage = image.flatten()\n",
        "\n",
        "\t\tdata.append(image)\n",
        "\n",
        "\tlabels = [1 if f.split(\"/\")[-1][0] == 'W' else 0 for f in file_list]\n",
        "\n",
        "\n",
        "\treturn np.array(data), np.array(labels)\n",
        " \n",
        "def ImgArray(file_list):\n",
        "\toutputArray=[]\n",
        "\tfor i, file in enumerate(file_list):\n",
        "\t\timage = io.imread(file)\n",
        "\t\toutputArray.append(image)\n",
        "\treturn np.array(outputArray)\n",
        " \n",
        " \n",
        "def folderToImgArray(ImgPath):\n",
        "\timlist = glob.glob(os.path.join(ImgPath, '*.jpg'))\n",
        "\timlist.sort()\n",
        "\toutput= ImgArray(imlist)\n",
        "\treturn output\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "16_cde0yxeqX",
        "outputId": "6ff9b11d-85a4-423b-b88c-c72b83e27db8"
      },
      "outputs": [],
      "source": [
        "# #loading list of images\n",
        "# #path=\"/content/drive/MyDrive/WormTracker/LabeledImgs/\" #path to image folder\n",
        "# path=\"/content/drive/MyDrive/WormTracker/WormImgs/\"\n",
        "# imlist = glob.glob(os.path.join(path, '*.jpg')) #pulls list of all files in folder\n",
        "# print('Dataset contains {} images'.format(len(imlist))) #returns how many images in list\n",
        "# listlen= len(imlist)\n",
        "\n",
        "# print(imlist) #For some reason, glob pulls the files in a wrong order\n",
        "# imlist.sort() #this sorts them alphabetically ASSUMES IMAGES ARE NUMBERED ALREADY/PROPERLY\n",
        "# print(imlist)\n",
        "\n",
        "# # Load the data. The same as pollen dataset read-skimage (May take a few seconds)\n",
        "# #data,labels = dataset(imlist) \n",
        "# data,labels= dataset(imlist)\n",
        "# data= np.array(data)\n",
        "# print(labels)\n",
        "# #this loads the images as a numpy ndarray with each image represented as matrix of pixel values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "kU2ns-Bc4-Gx"
      },
      "outputs": [],
      "source": [
        "## This block gets the list of x,y positions for each frame\n",
        "\n",
        "def getPosList(imgArray, stepSize='1'):\n",
        "  stepSize=5\n",
        "  #poslist= np.zeros((listlen-1, 2)) #x,y\n",
        "  poslist= np.empty((0,2), int)\n",
        "\n",
        "\n",
        "  for i in range(0,listlen-1,stepSize):\n",
        "    img1=imgArray[i,:,:,:]\n",
        "    img2=imgArray[i+1,:,:,:]\n",
        "\n",
        "    #frame_compare\n",
        "    pos=frame_compare(img1,img2)\n",
        "    #print(pos)\n",
        "    \n",
        "    poslist= np.append(poslist,np.array([pos]),axis=0)\n",
        "    #All i want to do is add new paired x and y values to a new row... how is this\n",
        "    #so much to ask\n",
        "\n",
        "\n",
        "\n",
        "  return poslist\n",
        "\n",
        "#poslist= getPosList(data,5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "lLq8Owpz4cRB"
      },
      "outputs": [],
      "source": [
        "\n",
        "# plt.scatter(poslist[:,0],poslist[:,1] )\n",
        "# plt.gca().invert_yaxis()\n",
        "# plt.xlim([0, 512])\n",
        "# plt.ylim([0,400])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "TJcLLEvIR-HO"
      },
      "outputs": [],
      "source": [
        "def pullSub(inImg, pos, outputSize):\n",
        "  if outputSize[0]>inImg.shape[0] or outputSize[1]>inImg.shape[1]:\n",
        "    return \"output bigger than image\"\n",
        "  xmin=int(pos[0]-(outputSize[0]/2))\n",
        "  xmax=int(pos[0]+(outputSize[0]/2))\n",
        "  ymin=int(pos[1]-(outputSize[1]/2))\n",
        "  ymax=int(pos[1]+(outputSize[1]/2))\n",
        "  if xmin<0:\n",
        "    xmin=0\n",
        "  if xmax>(inImg.shape[1]):\n",
        "    xmax=(inImg.shape[1]-1)\n",
        "  if ymin<0:\n",
        "    ymin=0\n",
        "  if ymax>(inImg.shape[0]):\n",
        "    ymax=(inImg.shape[0]-1)\n",
        "\n",
        "  subImg=inImg[ymin:ymax, xmin:xmax]\n",
        "\n",
        "  return subImg\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "END OF HELPER FXNS"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 285
        },
        "id": "mvtMGP6EGXM7",
        "outputId": "4e156031-355b-4daf-9267-2a45bd9eebde"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "<matplotlib.image.AxesImage at 0x7f41ceff53d0>"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        "a= pullSub(img2, pos1, [64,64])\n",
        "plt.imshow(a)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y5-u9jBdOVMM",
        "outputId": "10866f9d-8bc7-4175-d34c-bc6414e2cd74"
      },
      "outputs": [],
      "source": [
        "# #JUST A LITTLE TEST BLOCK\n",
        "# ldseg = glob.glob(os.path.join(path, '*.jpg')) #pulls list of all files in folder\n",
        "# print('Dataset contains {} images'.format(len(ldseg))) #returns how many images in list\n",
        "# listlen= len(ldseg)\n",
        "\n",
        "# print(ldseg) #For some reason, glob pulls the files in a wrong order\n",
        "# ldseg.sort() #this sorts them alphabetically ASSUMES IMAGES ARE NUMBERED ALREADY/PROPERLY\n",
        "# print(ldseg)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NXGstJf4fbTX",
        "outputId": "669dd9e3-485c-4241-ea4f-150ec54795c4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "38\n",
            "(8, 2)\n"
          ]
        }
      ],
      "source": [
        "#Display images in series that show tracking\n",
        "import time\n",
        "def displayTrack(pathToImages, stepSize=5):\n",
        "  imgPath=pathToImages\n",
        "  imgArray= folderToImgArray(imgPath)\n",
        "  listlen=imgArray.shape[0]\n",
        "  print(listlen)\n",
        "\n",
        "  #poslist= np.zeros((listlen-1, 2)) #x,y\n",
        "  poslist= np.empty((0,2), int)\n",
        "\n",
        "\n",
        "  for i in range(0,listlen-1,stepSize):\n",
        "    img1=imgArray[i,:,:,:]\n",
        "    img2=imgArray[i+1,:,:,:]\n",
        "\n",
        "    #frame_compare\n",
        "    pos=frame_compare(img1,img2)\n",
        "    #print(pos)\n",
        "    plt.close()\n",
        "    poslist= np.append(poslist,np.array([pos]),axis=0)\n",
        "  print(poslist.shape)\n",
        "\n",
        "  for i in range(0,poslist.shape[0]):\n",
        "    plt.imshow(imgArray[i*stepSize])\n",
        "    plt.scatter(poslist[i,0],poslist[i,1])\n",
        "    time.sleep(.5)\n",
        "    plt.close()\n",
        "\n",
        "displayTrack('D:\\WormTrack\\WormData\\wormimgs_lowqual\\\\')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "sixuP8UCntlU"
      },
      "outputs": [],
      "source": [
        "imgArray= folderToImgArray('/content/drive/MyDrive/WormTracker/WormImgs/')\n",
        "\n",
        "# for i in range(0,5):\n",
        "#   plt.figure()\n",
        "#   plt.imshow(imgArray[i,:,:,:])\n",
        "#   time.sleep()\n",
        "\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        " \n",
        "width = 1280\n",
        "height = 720\n",
        "channel = 3\n",
        " \n",
        "fps = 10\n",
        "sec = 3\n",
        " \n",
        "# Syntax: VideoWriter_fourcc(c1, c2, c3, c4) # Concatenates 4 chars to a fourcc code\n",
        "#  cv2.VideoWriter_fourcc('M','J','P','G') or cv2.VideoWriter_fourcc(*'MJPG)\n",
        " \n",
        "fourcc = cv2.VideoWriter_fourcc(*'MP4v') # FourCC is a 4-byte code used to specify the video codec.\n",
        "# A video codec is software or hardware that compresses and decompresses digital video. \n",
        "# In the context of video compression, codec is a portmanteau of encoder and decoder, \n",
        "# while a device that only compresses is typically called an encoder, and one that only \n",
        "# decompresses is a decoder. Source - Wikipedia\n",
        " \n",
        "#Syntax: cv2.VideoWriter( filename, fourcc, fps, frameSize )\n",
        "video = cv2.VideoWriter('test.mp4', fourcc, float(fps), (width, height))\n",
        " \n",
        "for frame_count in range(fps*sec):\n",
        "    img = imgArray[frame_count]\n",
        "    video.write(img)\n",
        " \n",
        "video.release()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n-OK8UaZspBI"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "e8D27rgzPGjq"
      },
      "source": [
        "Label all these images\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xgY6vyoWPKxC"
      },
      "outputs": [],
      "source": [
        "#This block of code is so sick and took me ages- J\n",
        "#Use this block to auto-generate annotated images to use for training\n",
        "#Give an input path containing a series of sequential worm images\n",
        "#It will track the worm with motion sensing, guess where it is\n",
        "#Based on that guess, it will save an image containing the worm, labeled with a W\n",
        "#Then grab a random image from another portion of the original, that will not contain a worm, labeled N\n",
        "\n",
        "import cv2\n",
        "import random\n",
        "\n",
        "def labeledSubImg(imgA,imgB,imgDim):\n",
        "  motionPos= frame_compare(imgA, imgB)\n",
        "\n",
        "  motionImg= pullSub(imgB,motionPos,imgDim)\n",
        "\n",
        "  randx= random.randrange(0+imgDim[1],imgB.shape[1]-imgDim[1])\n",
        "  randy= random.randrange(0+imgDim[0],imgB.shape[0]-imgDim[0])\n",
        "  count=0\n",
        "  while (randx>(motionPos[0]-round(imgDim[1]/2)) and randx<(motionPos[0]+round(imgDim[1]/2))) and (randy>(motionPos[1]-round(imgDim[0]/2)) and randy<(motionPos[1]+round(imgDim[0]/2))):\n",
        "    randx= random.randrange(0+imgDim[1],imgB.shape[1]-imgDim[1])\n",
        "    randy= random.randrange(0+imgDim[0],imgB.shape[0]-imgDim[0])\n",
        "    count+= 1\n",
        "    if count >30:\n",
        "      randx= 0+imgDim[1]\n",
        "      randy= 0+imgDim[0]\n",
        "      print('randomization took too long')\n",
        "      break\n",
        "  nonMotionImg= pullSub(imgB,[randx,randy],imgDim)\n",
        "  plt.subplot(1,2,1)\n",
        "  plt.imshow(motionImg)\n",
        "  plt.subplot(1,2,2)\n",
        "  plt.imshow(nonMotionImg)\n",
        "  print(motionPos)\n",
        "  print(randx,randy)\n",
        "  return motionImg, nonMotionImg\n",
        "  \n",
        "    \n",
        "\n",
        "def makeClassifierImages(imgPath, outputPath, imgDimensions, indexStart=0):\n",
        "  #ImgDimensions in a Rows,Columns notation\n",
        "  #pos as X,Y notation\n",
        "  path=imgPath\n",
        "  imgDimensions= list(imgDimensions)\n",
        "  imgList= glob.glob(os.path.join(path, '*.jpg'))\n",
        "  listLen= len(imgList)\n",
        "  imgList.sort()\n",
        "\n",
        "  for i in range(0,listLen-1):\n",
        "    imgA= io.imread(imgList[i])\n",
        "    imgB= io.imread(imgList[i+1])\n",
        "  #imgA= io.imread(imgList[1])\n",
        "  #imgB= io.imread(imgList[2])\n",
        "    subImg,nonMotionImg= labeledSubImg(imgA,imgB,imgDimensions)\n",
        "    \n",
        "    cv2.imwrite(outputPath+ '{0}imgLabeled_{1}.jpg'.format(\"W\",(numToIndex(i+indexStart,4))), subImg)\n",
        "    cv2.imwrite(outputPath+ '{0}imgLabeled_{1}.jpg'.format(\"N\",(numToIndex(i+indexStart,4))), nonMotionImg)\n",
        "\n",
        "\n",
        "\n",
        "#makeClassifierImages('/content/drive/MyDrive/WormTracker/WormImgs/','/content/drive/MyDrive/WormTracker/LabeledImgs/', [64,64])\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QhRFnr9M4tFe"
      },
      "source": [
        "NOW THE NEURAL NETWORK:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Whhxgiq76CpJ"
      },
      "outputs": [],
      "source": [
        "dataPath = '/content/drive/My Drive/WormTracker/LabeledImgs/'\n",
        "imgsList= glob.glob(os.path.join(dataPath, '*.jpg')) #pulls list of all files in folder\n",
        "listlen= len(imgsList)\n",
        "imgsList.sort() #this sorts them alphabetically ASSUMES IMAGES ARE NUMBERED ALREADY/PROPERLY\n",
        "print(imgsList)\n",
        "trainData,labels= dataset(imgsList, (64,64)) #trainData is now an array of images, labels is an array of label values 0/1\n",
        "print(labels)\n",
        "print(trainData.shape)\n",
        "# Create a training and testing dataset with 25% of the samples\n",
        "X_train, X_test, y_train, y_test = train_test_split(trainData,labels, test_size=.25,random_state=0,)\n",
        "#ids=np.array(range(data.shape[0]))\n",
        "#X_train, X_ids, y_train, y_ids = train_test_split(data,ids, test_size=.25,random_state=0,)\n",
        "#X_test=labels[X_ids]; y_test=labels[y_ids]\n",
        "print('Done')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6DWhGf-46BxY"
      },
      "outputs": [],
      "source": [
        "# check shape of the input image to fit with the network \n",
        "print(X_train.shape)\n",
        "print(X_test.shape)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HzUohCNl5jqH"
      },
      "outputs": [],
      "source": [
        "import skimage\n",
        "#These were original values, I reduced to 64x64 because we already took down to that size\n",
        "X_train_resized = np.asarray([skimage.transform.resize(image, (224,224)) for image in X_train])\n",
        "X_test_resized = np.asarray([skimage.transform.resize(image, (224,224)) for image in X_test])\n",
        "\n",
        "#X_train_resized = np.asarray([skimage.transform.resize(image, (64,64)) for image in X_train])\n",
        "#X_test_resized = np.asarray([skimage.transform.resize(image, (64,64)) for image in X_test])\n",
        "\n",
        "print(X_train_resized.shape)\n",
        "print(X_test_resized.shape)\n",
        "# plt.subplot(1,2,1)\n",
        "# plt.imshow(X_train[2,:,:,:])\n",
        "# plt.subplot(1,2,2)\n",
        "# plt.imshow(X_train_resized[2,:,:,:])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "XZ33bVFA5kXA"
      },
      "outputs": [],
      "source": [
        "y_train_encoded = to_categorical(y_train)\n",
        "y_test_encoded = to_categorical(y_test)\n",
        "\n",
        "y_train_encoded.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9zVzQrXG47kR"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import os\n",
        "import cv2\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import backend as K\n",
        "from tensorflow.keras.layers import Dense, Activation,Dropout,Conv2D, MaxPooling2D,BatchNormalization, Flatten\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.metrics import categorical_crossentropy\n",
        "from tensorflow.keras import regularizers\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n",
        "from tensorflow.keras.applications import imagenet_utils\n",
        "from tensorflow.keras.preprocessing import image\n",
        "from tensorflow.keras.models import Model, load_model, Sequential\n",
        "from tensorflow.keras.utils import to_categorical\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "\n",
        "\n",
        "train_gen=ImageDataGenerator(preprocessing_function=keras.applications.mobilenet.preprocess_input,\n",
        "                horizontal_flip=True,\n",
        "                samplewise_center=True,\n",
        "                width_shift_range=.2,\n",
        "                height_shift_range=.2,                \n",
        "                samplewise_std_normalization=True).flow(X_train_resized, y_train_encoded)\n",
        "#val_gen=ImageDataGenerator(preprocessing_function=keras.applications.mobilenet.preprocess_input,\n",
        "#                samplewise_center=True,                \n",
        "#                samplewise_std_normalization=True).flow(xValid, yValid, shuffle=False)        \n",
        "test_gen=ImageDataGenerator(preprocessing_function=keras.applications.mobilenet.preprocess_input,\n",
        "                samplewise_center=True,                \n",
        "                samplewise_std_normalization=True).flow(X_test_resized, y_test_encoded, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zCNxuWww5RCW"
      },
      "outputs": [],
      "source": [
        "Top=False\n",
        "weights=None\n",
        "layer_cut=-6\n",
        "lr_rate=.001\n",
        "rand_seed=128\n",
        "epochs=25\n",
        "mobile = tf.keras.applications.mobilenet.MobileNet( include_top=Top,\n",
        "                                                           input_shape=(224,224,3),\n",
        "                                                           pooling='avg', weights='imagenet',\n",
        "                                                          )  #was 224,224,3\n",
        "                 \n",
        "x=mobile.layers[layer_cut].output\n",
        "x = Flatten()(x)\n",
        "x=Dense(128, kernel_regularizer = regularizers.l2(l = 0.015), activation='relu')(x)\n",
        "\n",
        "x=Dropout(rate=.5, seed=rand_seed)(x)\n",
        "predictions=Dense (2, activation='softmax')(x)\n",
        "model = Model(inputs=mobile.input, outputs=predictions)\n",
        "        \n",
        "for layer in model.layers:\n",
        "    layer.trainable=True\n",
        "model.compile(Adam(lr=lr_rate), loss='categorical_crossentropy', metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oH5t_ySjw9lf"
      },
      "outputs": [],
      "source": [
        "#Trying to figure out what the purpose of changing x is\n",
        "#I get that he's manipulating each layer, but is the memory of each operation stored in x?\n",
        "#are the predictions: layer[-6] -> flattened ->dense -> dropout -> dense\n",
        "#I'm going to assume thats the case, I just dont know how else layers are added to a model\n",
        "\n",
        "print(mobile.layers)\n",
        "x=mobile.layers[layer_cut].output\n",
        "print(mobile.layers[-6].output)\n",
        "x = Flatten()(x)\n",
        "print(x)\n",
        "x=Dense(128, kernel_regularizer = regularizers.l2(l = 0.015), activation='relu')(x)\n",
        "print(x)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5AkLs7bxw-aR"
      },
      "outputs": [],
      "source": [
        "x,y  = train_gen.next()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r_bOx88vxAnJ"
      },
      "outputs": [],
      "source": [
        "# set ansi color values\n",
        "Cblu ='\\33[34m'\n",
        "Cend='\\33[0m'   # sets color back to default \n",
        "Cred='\\033[91m'\n",
        "Cblk='\\33[39m'\n",
        "Cgreen='\\33[32m'\n",
        "Cyellow='\\33[33m'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TFNXljcdxC5R"
      },
      "outputs": [],
      "source": [
        "start_epoch=0\n",
        "start=time.time()\n",
        "results = model.fit_generator(generator = train_gen, validation_data= test_gen, epochs=epochs, initial_epoch=start_epoch, verbose=1)\n",
        "stop=time.time()\n",
        "duration = stop-start\n",
        "hrs=int(duration/3600)\n",
        "mins=int((duration-hrs*3600)/60)\n",
        "secs= duration-hrs*3600-mins*60\n",
        "msg='{0}Training took\\n {1} hours {2} minutes and {3:6.2f} seconds {4}'\n",
        "print(msg.format(Cblu,hrs, mins,secs,Cend))\n",
        "tacc=results.history['accuracy']\n",
        "tloss=results.history['loss']\n",
        "vacc=results.history['val_accuracy']\n",
        "vloss=results.history['val_loss']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VYchQBjVxIAS"
      },
      "outputs": [],
      "source": [
        "Epoch_count=len(tloss)\n",
        "Epochs=[]\n",
        "for i in range (0,Epoch_count):\n",
        "    Epochs.append(i+1)\n",
        "index_loss=np.argmin(vloss)#  this is the epoch with the lowest validation loss\n",
        "val_lowest=vloss[index_loss]\n",
        "index_acc=np.argmax(vacc)\n",
        "val_highest=vacc[index_acc]\n",
        "plt.style.use('fivethirtyeight')\n",
        "sc_label='best epoch= '+ str(index_loss+1)\n",
        "vc_label='best epoch= '+ str(index_acc + 1)\n",
        "fig,axes=plt.subplots(nrows=1, ncols=2, figsize=(15,5))\n",
        "axes[0].plot(Epochs,tloss, 'r', label='Training loss')\n",
        "axes[0].plot(Epochs,vloss,'g',label='Validation loss' )\n",
        "axes[0].scatter(index_loss+1,val_lowest, s=150, c= 'blue', label=sc_label)\n",
        "axes[0].set_title('Training and Validation Loss')\n",
        "axes[0].set_xlabel('Epochs')\n",
        "axes[0].set_ylabel('Loss')\n",
        "axes[0].legend()\n",
        "axes[1].plot (Epochs,tacc,'r',label= 'Training Accuracy')\n",
        "axes[1].plot (Epochs,vacc,'g',label= 'Validation Accuracy')\n",
        "axes[1].scatter(index_acc+1,val_highest, s=150, c= 'blue', label=vc_label)\n",
        "axes[1].set_title('Training and Validation Accuracy')\n",
        "axes[1].set_xlabel('Epochs')\n",
        "axes[1].set_ylabel('Accuracy')\n",
        "axes[1].legend()\n",
        "plt.tight_layout\n",
        "#plt.style.use('fivethirtyeight')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vkkRNZnOxKn_"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "cf=confusion_matrix(y_test, preds, labels=[0,1])\n",
        "\n",
        "import pandas as pd\n",
        "df=pd.DataFrame(cf,columns=['pred NP','pred P'],index=['true NP','true P'])\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gKRiRE-9xMRJ"
      },
      "outputs": [],
      "source": [
        "idx=100;\n",
        "#pred=model.predict(X_test[[idx],...])\n",
        "plt.imshow(X_test[idx])\n",
        "plt.grid(False)\n",
        "plt.title(\"Score {:.3f} / Truth {}\".format(preds[idx][1], y_test[idx]) )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WuIeYZlkxOQ4"
      },
      "outputs": [],
      "source": [
        "# contact sheet\n",
        "visualize(X_test,y_test,decisions,rawscores,sortids)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyMBKZk8YctehJvqMni4y/F6",
      "include_colab_link": true,
      "mount_file_id": "1JGMc-_phb1unBHk_Mu4862LX-a_4kjXZ",
      "name": "WormTrackerV2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
